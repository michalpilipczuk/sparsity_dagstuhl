\paragraph*{Theoretical eyes of an algorithm designer.} 
Combinatorial methods developed in the study of classes of sparse graphs turned out to be very useful in the design of algorithms, in particular within the framework of {\em{parameterized complexity}}.
In this area, the goal is develop algorithms whose running time is measured not only in terms of the total input size, but also secondary measures called {\em{parameters}} that govern the actual 
difficulty of the instance. The usual goal here is to show that a problem is {\em{fixed-parameter tractable}}, that is, 
design an algorithm that runs in time $f(k)\cdot n^c$, where $n$ is the input size, $k$ is the parameter (or a vector of parameters), 
$f$ is a computable function, and $c$ is a universal constant, independent of $k$.
This philosophy very well matches the toolbox of sparsity, which provides a wealth of parameters measuring structural sparsity of graphs, such as generalized coloring numbers or
low-treedepth colorings. Historically, the study of parameterized algorithms on sparse structures focused on the cases of graphs of bounded degree and on proper minor-closed classes, with a particular focuse on
planar graphs and graphs of bounded tree-width.

Note that all the abovementioned settings can be subsumed by the concepts of bounded expansion and nowhere denseness.
It turns out that for certain general type of problems, these structural sparsity notions form a very suitable context of study, yielding conceptually simpler, yet more general reasonings than 
in the case of proper minor-closed classes. Not surprisingly, the techniques are best-suited to problems with a local character:
one looks for a solution (say, subset of vertices) that admits a property that can be checked by inspecting a constant-depth neighborhood of every vertex.
Example problems of this kind are the following: Subgraph Isomorphism (given graphs $H$ and $G$, check whether $H$ is a subgraph of $G$), Distance-$r$ Independent Set (given a graph $G$, find as many as possible
vertices pairwise at distance more than $r$), and Distance-$r$ Dominating Set (given a graph $G$, use as few vertices as possible to dominate it, 
where every vertex dominates all vertices at distance at most $r$ from it).
The study of these particular problems in the context of structural sparsity inspired a range of new algorithmic techniques, based on different combinatorial tools.

The notion of {\em{low tree-depth decompositions}} introduced by Ne\v{s}et\v{r}il and Ossona de Mendez~\cite{NesetrilM08a} was directly inspired by algorithmic layering techniques known from the planar setting,
and provides alternative combinatorial characterizations of bounded expansion and nowhere denseness.
One of the first applications, observed in~\cite{NesetrilM08a}, is a linear-time fixed-parameter algorithm for Subgraph Isomorphism on any class of bounded expansion.
%which provides the base, existential case for first-order model-checking. 
The fixed-parameter tractability of Distance-$r$ Dominating Set on any nowhere dense class was proved by Dawar and Kreutzer~\cite{DawarK09}, 
who used the characterization of nowhere denseness via {\em{uniform quasi-wideness}} to this aim.
This line of research was continued by Drange et al.~\cite{DrangeDFKLPPRVS16} and by Eickmeyer et al.~\cite{eickmeyer2016neighborhood}, 
who gave a linear kernel for the problem on any class of bounded expansion and an almost linear kernel on any nowhere dense class, respectively.
These works highlighted the combinatorial concept of {\em{neighborhood complexity}} as a useful way of defining structural sparsity, 
which was later generalized and connected to concepts from stability theory by Pilipczuk et al.~\cite{pilipczuk2018number}.
It turns out that for subgraph-closed classes the notion of nowhere denseness is the ultimate limit of fixed-parameter tractability for Distance-$r$ Dominating Set,
under plausible complexity assumptions~\cite{DrangeDFKLPPRVS16}. This, together with a similar dichotomy result for model-checking first-order logic that we discuss later,
validates the fundamental nature of the notion of nowhere denseness: it is the natural of tractability for local problems on subgraph-closed classes of graphs.

The study of duality between distance-$2r$ independence and distance-$r$ domination led Dvo\v{r}\'ak~\cite{Dvorak13}
to the development of constant-factor approximation algorithms for both problems on any class of bounded expansion.
The algorithm of Dvo\v{r}\'ak is remarkably simple and it relies on {\em{generalized coloring numbers}}, which influenced a widespread usage of this approach in algorithmic aspects of sparsity.
This applies in particular to the setting of {\em{distributed algorithms}}, because using generalized coloring numbers can be used to compute sparse {\em{neighborhood covers}}: 
a covering of a graph using local clusters that enables localization of computation and, thus, facilitates distributed treatment.
Using these ideas, Amiri et al.~\cite{AmiriMRS18} gave a distributed constant factor approximation algorithm for Distance-$r$ Dominating Set on any class of bounded expansion running in a logarithmic number of rounds.
A distributed variant of the algorithm for Subgraph Isomorphism running in a logarithmic number of rounds was presented by Ne\v{s}et\v{r}il and Ossona de Mendez~\cite{NesetrilM16}.

Recently, sparsity methods were successfully applied to give new algorithmic results in the settings of {\em{circuit complexity}}~\cite{PilipczukST18} 
(a model for {\em{parallel algorithms}}), {\em{property testing}}~\cite{AdlerH18}, and {\em{approximation schemes}}~\cite{Har-PeledQ17}.


